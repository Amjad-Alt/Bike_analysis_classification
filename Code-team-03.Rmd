---
title: "Model Building Techniques- CoGo Bike Share Data"
author: "Team - 03"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: no
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
  word_document:
    toc: yes
    toc_depth: '3'
---


```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
library(purrr)   #to join all files
library(lubridate)# for duration of time
library(ModelMetrics)
library(pROC)
library(dplyr)
library(tidyr)
library(caret)
library(ggplot2)
library(ezids)
library(class)
library(gmodels)
library(FNN)

```


#Source of Dataset and observation
We are using 6 months of data covering Quarter 2 and Quarter 3 (6 months) [Not covering the entire year due to the large size of the data]
```{r, results='markup'}

#binding all the files in this path together
file.list <- list.files(pattern='*.csv')

file.list <- setNames(file.list, file.list)

bike <-map_df(file.list, function(x) read.csv(x))

str(bike)

```
#Features in the dataset
Below are all the column names of the dataset
```{r, results='markup'}

colnames(bike)

```

# Data preparation

Data contains 3 types of bikes- Classic, Electric and Docked. We are removing docked bike from the data to balance the data as the data contains only 8 docked bikes.
```{r, results='markup'}

bike%>%group_by(rideable_type)%>%
  summarise(count = n())

#Remove docked bikes
bike <-subset(bike, rideable_type != "docked_bike")

bike%>%group_by(rideable_type)%>%
  summarise(count = n())

```
#Preparing columns for modeling
```{r, results='markup'}

bike$rideable_type <- factor(ifelse(bike$rideable_type=="classic_bike",0,1))
bike$start_station_id <- factor(bike$start_station_id)
bike$end_station_id <- factor(bike$end_station_id)
bike$member_casual<-factor(ifelse(bike$member_casual=='casual',0,1))

# Formatting started_at and ended_at column to date and time column
bike$start_time <- format(as.POSIXct(bike$started_at), format = "%H:%M")
bike$end_time <- format(as.POSIXct(bike$ended_at), format = "%H:%M") 

# Fixing the date format to get the time difference
bike$Startedat = as.POSIXct(bike$started_at, format = "%Y-%m-%d %H:%M:%S")
bike$enddat = as.POSIXct(bike$ended_at, format = "%Y-%m-%d %H:%M:%S")

#Calculating the time difference 
bike$Total_Time <- abs(as.numeric(difftime(bike$enddat, bike$Startedat, units = "mins")))

#Extracting the day from the date
bike$start_date <- as.Date(bike$started_at)
bike$end_date <- as.Date(bike$ended_at)
bike$days <- factor(format(bike$start_date, format = "%a"))

#Converting time in minutes
res <- hm(bike$start_time)# format to 'hours:minutes'
bike$startingm <- hour(res)*60 + minute(res)

res <- hm(bike$end_time)# format to 'hours:minutes'
bike$endingm <- hour(res)*60 + minute(res)

# Extract the 'Hours' only first, then change it to numeric variable
bike$start_hour <- format(as.POSIXct(bike$started_at), format = "%H")
bike$start_hour <- as.numeric(bike$start_hour)
# Use 'summary(bike$start_hour_num)' to check if the min and max are 0 and 23

# Divide the time into different categories/intervals

bike$Time_range <- cut(bike$start_hour, c(0, 6, 12, 18, 23), c("Before dawn", "Morning", "Afternoon", "Night"), include.lowest=TRUE)
#0am-6am : Morning (Factor 1)
#6am-12pm : Morning (Factor 2)
#12pm-18pm : Afternoon (Factor 3)
#6pm-0am : Night (Factor 4)

# Double check the structure to make sure if we do that successfully
str(bike)

print(head(bike))

str(bike)

```

#selecting the features needed for the model and removing NA values from the data
```{r, results='markup'}

#selecting the features needed for the model

selected_features <- c('member_casual','rideable_type', 'Total_Time', 'start_station_id', 'end_station_id', 'startingm','endingm','days', 'start_hour', 'Time_range')

bike2 <- bike[,(names(bike) %in% selected_features)]

#Removing NA values

bike2<-na.omit(bike2)

str(bike2)

```

SMART Questions:

1. How much time will the customer (Annual membership or Casual) ride the bike if travelling from a certain station to another or using a certain bike etc? 
#----------------------- Chris Code start-----------------------------
## Objective
We are going to use the newly created variable 'Total_Time' and want to make a fitted and predictive model for the customer’s riding time. This is because:
1). As we said before, COGO's sharing bike price is defined by the riding time instead of riding distance.
2). If we can get some information from the model about what factors can affect customer's riding time and how did they affect, for example, which customer type has more impact on the riding time, or, which bike type has more impact on the riding time.....etc.
3). If we can figure out the pattern of factors affecting riding time from our model, we can make some recommendations for the company's profit margin. 
## Model structure
### Subset to 4 datasets based on time range
```{r}
bike_lm <- data.frame(bike2)

```

```{r}
bike_lm1 <- lm(formula = Total_Time ~ start_hour+rideable_type+member_casual+days, data=bike_lm)
summary(bike_lm1)
plot(bike_lm1)
```
According to the model, bad fittings

## Model Assumptions Checking & Model Improvement:
The model is pretty bad fitting based on R-Squared
Because these fittings are really bad, so we are going to do something to improve the models:
### Multicollinearity check: 
According the information from previous Pre-Processing part, we had alraady checked that all variables are independent by VIF, but now because we added a new column/variable into our model, so we will just do the VIF check again
```{r}
library(car)
vif(bike_lm1)
```
As we see, all the VIFs are less than 5, which is acceptable, so our current model don't have the model of multicollinearity.
### Normally Shaped check:
We need to make sure the dependent variable is (approximate) normal. We can check the distribution of our response 'Total_variable' by building the its histogram
```{r}

# Double check the Total_Time distribution
ggplot(data=bike_lm, mapping = aes(Total_Time))+geom_histogram(col='red', fill='blue')+labs(title='Histogram for total riding time')
```
According to the distribution above, it's so right skewed and we can't use the variable with this distribution to build the linear regression. This may be a reason that we get a so bad fittings. Thus, we will try to exclude all the outliers and build the regression again to see if we can improve the model's fitting. 
```{r}

library(ezids)

bike_clean <- outlierKD2 (bike_lm, Total_Time, rm=T, boxplt = TRUE, qqplt = TRUE)
print('Summary Statistic for cleaned membership time')
summary(bike_lm$Total_Time)

# Double check the distribution 
# ggplot(data=bike_clean, mapping = aes(Total_Time))+geom_histogram(col='red', fill='blue')+labs(title='Histogram for total riding time')
```
Above we can see now the Total_Time's distribution is approximate normal, which is much better than before, and we can use it to build the linear model again.
```{r}
bike_lm2 <- lm(formula = Total_Time ~ (start_hour+rideable_type+member_casual+days)^2, data=bike_clean)
summary(bike_lm2)
plots(bike_lm2)

```
               
The model are better after we remove the outliers and the R-Squared values are went up a little bit. However, most of the models are still not having a good fitting , so we will keep checking other assumptions of linear model
## Linearity check
Let's check the scatter plot between start hour and the total time: 
```{r}
library(ggplot2)

qplot (x=start_hour, y=Total_Time, data=bike_lm, xlab='Start_hour', ylab='Total_time', main='scatter-plot Total_Time vs start_hour (General)') 
```
We can see there's totally no linear relationship with these two variable, but we can keep checking that if we divided the starting hour into different time range
We subsetted the start_hour into 4 different categories: Before dawn，Morning, Afternoon and Night
```{r}

bike_clean_before_dawn <- subset(bike_clean, Time_range=='Before dawn')
bike_clean_morning <- subset(bike_clean, Time_range=='Morning')
bike_clean_afternoon <- subset(bike_clean, Time_range =='Afternoon')
bike_clean_night <- subset(bike_clean, Time_range=='Night')

```
Then, let's check the scatter plot of the total riding time and starting hour within each different time range
```{r}

qplot (x=Total_Time, y=start_hour, data=bike_clean_before_dawn, xlab='Start_hour', ylab='Total_time', main='scatter-plot Total_Time vs start_hour (Before dawn)') 
qplot (x=Total_Time, y=start_hour, data=bike_clean_morning, xlab='Start_hour', ylab='Total_time', main='scatter-plot Total_Time vs start_hour (Morning)') 
qplot (x=Total_Time, y=start_hour, data=bike_clean_afternoon, xlab='Start_hour', ylab='Total_time', main='scatter-plot Total_Time vs start_hour (Afternoon)') 
qplot (x=Total_Time, y=start_hour, data=bike_clean_night, xlab='Start_hour', ylab='Total_time', main='scatter-plot Total_Time vs start_hour (Night)') 
```
We see there's still not any linear relationship between total time and starting hour. 
## Final Conclusion
However, there are still have some significance coefficients, even thouh we don't have a good fitting, which are the starting hour, and the interaction terms of starting hour affected by electrical bike and the interaction terms of electrical bike affected by casual customers. 
(Include brief regression tree description in here?)
Thus, finally we have to make a conclusion and say we can't answer the smart question about predicting total riding time with with the given dataset by linear regression model.

#----------------------- Chris Code End-----------------------------

2. Which Bike type (Electric or Manual) will the customer (Annual membership or Casual) use if travelling from a certain station to another/while using a certain bike type etc? 


We used 2 model to answer this question
1. Logistic Regression
2. KNN


Model-1: Logistic Regression (for Bike Type)

```{r, results='markup'}

#Copying data for the model
bike_RT_LR <- data.frame(bike2)

#df <- outlierKD2(df,Total_Time)

#making rideable_type the first column

colnames(bike_RT_LR)
bike_RT_LR <- bike_RT_LR %>%
  select('rideable_type', everything())

```

# Checking for unbalanced data
```{r, results='markup'}

bike_RT_LR%>%group_by(rideable_type)%>%
  summarise(count = n())

bike_RT_LR %>% count(rideable_type)
ggplot(bike_RT_LR, aes(rideable_type, fill = rideable_type))+
  geom_bar()+
  scale_fill_brewer(palette = "BuPu")+
  guides(fill="none")+
  labs(title = "User bike types", x= "bike types")+
  theme_classic()

```

#Test and train split
```{r, results='markup'}

#scaleddf <- as.data.frame(scale(df[2:13], center = TRUE, scale = TRUE))

set.seed(333)

bike_RT_LR_sample <- sample(2, nrow(bike_RT_LR), replace=TRUE, prob=c(0.75, 0.25))

bike_RT_LR_train_X <- bike_RT_LR[bike_RT_LR_sample==1, 2:8]
bike_RT_LR_test_X <- bike_RT_LR[bike_RT_LR_sample==2, 2:8]

bike_RT_LR_train_Y <- bike_RT_LR[bike_RT_LR_sample==1, 1]
bike_RT_LR_test_Y <- bike_RT_LR[bike_RT_LR_sample==2, 1]

str(bike_RT_LR_train_X)

```

# Logistic model
```{r, results='markup'}

Bike_Type_Logit <- glm(bike_RT_LR_train_Y ~ start_station_id+ end_station_id+Total_Time*member_casual+ startingm*days +endingm , data = bike_RT_LR_train_X, family = "binomial")
summary(Bike_Type_Logit)

```


# evaluating the model
```{r, results='markup'}

prob=predict(Bike_Type_Logit, type = "response")
a <- roc(bike_RT_LR_train_Y~prob)
auc(a) # area-under-curve 
plot(a)

```

#Check the accurcy for the test
```{r, results='markup'}

proc=predict(Bike_Type_Logit, type = "response", newdata = bike_RT_LR_test_X)
bike_RT_LR_test_X$proc=proc
b <- roc(bike_RT_LR_test_Y~proc)
print(b)
plot(b)

```

## McFadden
```{r, results='markup'}

library(pscl)
pR2(Bike_Type_Logit)

```


### Akaike Information Criterion (AIC)
```{r, results='markup'}

AIC(Bike_Type_Logit)

```

# Prediction
## At 0.5 cut
```{r, results='markup'}

logitpredict.5 <- predict(Bike_Type_Logit, newdata = bike_RT_LR_test_X, type = "response") > 0.55

defult <- ifelse(logitpredict.5 =="TRUE", 1, 0)
crossTable = table(defult,bike_RT_LR_test_Y)
t <- as.data.frame(crossTable)
crossTable
```

### plot confution metrix
```{r, results='markup'}

ggplot(data =  t, mapping = aes(x = defult, y = bike_RT_LR_test_Y)) +
  geom_tile(aes(fill = Freq), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
  scale_fill_gradient(low = "#98c1d9", high = "#8f2d56") +
  theme_bw() + 
  theme(legend.position = "none") +
  labs(title = "Confution Matrix with Cutoff at 0.05")+
  xlab( "predected")+
  ylab( "original")

```

###The accuracy of the model of 0.5 cutoff :
```{r, results='markup'}

format(100*(crossTable[1,1]+crossTable[2,2])/sum(crossTable), digits=4)

```

## At 0.4 cut
```{r, results='markup'}

logitpredict.4 <- predict(Bike_Type_Logit, newdata = bike_RT_LR_test_X, type = "response") > 0.6
defult2 <- ifelse(logitpredict.4 =="TRUE", 1, 0)
crossTable4 = table(defult2,bike_RT_LR_test_Y)
d <- as.data.frame(crossTable4)
crossTable4
```


### The accuracy of the model of 0.4 cutoff :
```{r, results='markup'}

format(100*(crossTable4[1,1]+crossTable4[2,2])/sum(crossTable4), digits=4)

```


```{r, results='markup'}

ggplot(data = d , mapping = aes(x = defult2, y = bike_RT_LR_test_Y)) +
  geom_tile(aes(fill = Freq), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
  scale_fill_gradient(low = "#98c1d9", high = "#8f2d56") +
  theme_bw() +
  theme(legend.position = "none")+
  labs(title = "Confution Matrix with Cutoff at 0.04")+
  xlab( "predected")+
  ylab( "original")

```
#Predicting with values
```{r, results='markup'}

glm1 <- data.frame(start_station_id= "15", end_station_id = "11", Total_Time = 2, member_casual = "0", startingm = 80, days = "Sun", endingm = 100)
predict(Bike_Type_Logit, newdata=glm1)

```

Model-2: KNN (for Bike Type)

#Copying data for the model
```{r, results='markup'}

df_knn <- data.frame(bike2)

print(head(df_knn))


#selecting the features needed for the model
selected_features <- c('member_casual','rideable_type', 'Total_Time', 'start_station_id', 'end_station_id', 'startingm','endingm')

df_rt_knn <- df_knn[,(names(df_knn) %in% selected_features)]

```


#Converting values into numeric
```{r, results='markup'}

#df_rt_knn <- as.data.frame(df_knn[-c(7)])
df_rt_knn$rideable_type <- as.numeric(df_knn$rideable_type)
df_rt_knn$Total_Time <- as.numeric(df_knn$Total_Time)
df_rt_knn$member_casual <- as.numeric(df_knn$member_casual)
df_rt_knn$start_station_id <- as.numeric(df_knn$start_station_id)
df_rt_knn$end_station_id <- as.numeric(df_knn$end_station_id)
df_rt_knn$startingm <- as.numeric(df_knn$startingm)
df_rt_knn$endingm <- as.numeric(df_knn$endingm)

print(head(df_rt_knn))

```



```{r, results='markup'}

scaleddf <- as.data.frame(scale(df_rt_knn[2:6], center = TRUE, scale = TRUE))
set.seed(333)
df_sample_rt <- sample(2, nrow(df_rt_knn), replace=TRUE, prob=c(0.75, 0.25))


DF_Rt_train_X <- df_rt_knn[df_sample_rt==1, 2:6]
DF_Rt_test_X <- df_rt_knn[df_sample_rt==2, 2:6]


DF_Rt_train_y <- df_rt_knn[df_sample_rt==1, 1]
DF_Rt_test_y <- df_rt_knn[df_sample_rt==2, 1]

df_rt_knn

```


```{r, results='markup'}


knn1 <- knn(train=DF_Rt_train_X, test=DF_Rt_test_X, cl=DF_Rt_train_y, k=5)

```

ResultDf = data.frame( k=numeric(0), Total.Accuracy= numeric(0), row.names = NULL )

for (kval in seq(11,50,2)) {
  nasa_pred <- knn(train = nasa_train, test = nasa_test, cl=nasa_train.labels, k=kval)
  #NASA_PREDCross = CrossTable(nasa_test.labels, nasa_pred, prop.chisq = FALSE)
  cm = confusionMatrix(nasa_pred, as.factor(nasa_test.labels) ) # from caret library
  cmaccu = cm$overall['Accuracy']
  cmt = data.frame(k=kval, Total.Accuracy = cmaccu, row.names = NULL ) # initialize a row of the metrics 
  ResultDf = rbind(ResultDf, cmt)
}
xkabledply(ResultDf, "Total Accuracy Summary:"

```{r, results='markup'}

knn_crosst <- gmodels::CrossTable(DF_Rt_test_y, train = knn1, prop.chisq = FALSE)

```

```{r, results='markup'}


# create an empty dataframe to store the results from confusion matrices
ResultDf = data.frame( k=numeric(0), Total.Accuracy= numeric(0), row.names = NULL )
kval = 3
knn_pred <- knn(train = DF_Rt_train_X, test = DF_Rt_test_X, cl=DF_Rt_train_y, k=kval)

knn_crosst <- gmodels::CrossTable(DF_Rt_test_y, train = knn_pred, prop.chisq = FALSE)
print( paste("k = ", kval) )
knn_crosst

```

```{r, results='markup'}

library(caret)

cm <- confusionMatrix(knn_pred, reference = as.factor(DF_Rt_test_y)) 


cmaccu = cm$overall['Accuracy']
print( paste("Total Accuracy = ", cmaccu ) )


cmt = data.frame(k=kval, Total.Accuracy = cmaccu, row.names = NULL ) 

ResultDf = rbind(ResultDf, cmt)
print(as.matrix(cm), title = paste("ConfusionMatrix for k = ",kval ) )
```

```{r, results='markup'}


cmt = data.frame(k=kval, Total.Accuracy = cmaccu, row.names = NULL ) 
ResultDf = rbind(ResultDf, cmt)
print(as.matrix(cm), title = paste("ConfusionMatrix for k = ",kval ) )


```

```{r, results='markup'}
print(data.frame(cm$byClass), title=paste("k = ",kval))

```

# Different K-values
```{r, results='markup'}

for (kval in 4:11) {
  knn_pred <- knn(train = DF_Rt_train_X, test = DF_Rt_test_X, cl=DF_Rt_train_y, k=kval)
  knn_crosst <- CrossTable(DF_Rt_test_y, knn_pred, prop.chisq = FALSE)
  print( paste("k = ", kval) )
  knn_crosst
  # 
  cm = confusionMatrix(knn_pred, reference = as.factor(DF_Rt_test_y)) 
  
  cmaccu = cm$overall['Accuracy']
  print( paste("Total Accuracy = ", cmaccu ) )

  cmt = data.frame(k=kval, Total.Accuracy = cmaccu, row.names = NULL ) 
  
  ResultDf = rbind(ResultDf, cmt)
  print(as.matrix(cm), title = paste("ConfusionMatrix for k = ",kval ) )
  print(data.frame(cm$byClass), title=paste("k = ",kval))
}

```


```{r, results='markup'}
print(ResultDf, "Total Accuracy Summary")
```
2. What type of customer (Annual membership or Casual) will travel from a certain station to another, while using a particular bike?

We built 1 model for this question

Model-1: Logistic Regression (for Customer Type)

```{r, results='markup'}

#Copying data for the model
df <- data.frame(bike2)

# delete outliers
df <- outlierKD2(df,Total_Time)

#making rideable_type the first column

colnames(df)
df <- df %>%
  select('member_casual', everything())

```

# Checking for unbalanced data
```{r, results='markup'}

bike_RT_LR%>%group_by(rideable_type)%>%
  summarise(count = n())

bike_RT_LR %>% count(rideable_type)
ggplot(bike_RT_LR, aes(rideable_type, fill = rideable_type))+
  geom_bar()+
  scale_fill_brewer(palette = "BuPu")+
  guides(fill="none")+
  labs(title = "User bike types", x= "bike types")+
  theme_classic()

```

# Check if we have unbalanced data
```{r}
df%>%group_by(member_casual)%>%
  summarise(count = n())

df %>% count(member_casual)
ggplot(df, aes(member_casual, fill = member_casual))+
  geom_bar()+
  scale_fill_brewer(palette = "BuPu")+
  guides(fill="none")+
  labs(title = "User membersip types", x= "types of memebership")+
  theme_classic()
```

```{r}
# Correlation matrix

```

```{r}
# Multicollinearitly 

```

# scale and devide the data
```{r}
#scaleddf <- as.data.frame(scale(df[2:13], center = TRUE, scale = TRUE))
set.seed(321)
df_sample <- sample(2, nrow(df), replace=TRUE, prob=c(0.75, 0.25))


train_X <- df[df_sample==1, 2:8]
test_X <- df[df_sample==2, 2:8]


train_y <- df[df_sample==1, 1]
test_y <- df[df_sample==2, 1]

str(train_X)
```

# Logistic model
```{r}
#deleted start_station_id and Wed coz the model says it is not much predictable 
customerLogit <- glm(train_y ~ end_station_id+Total_Time+rideable_type+ startingm*days + endingm + start_station_id, data = train_X, family = "binomial")
summary(customerLogit)
```

# See how well the model is doing by running suveral tests:
## Deviance tests
### A GOF deviance test for the null model:
```{r}  

p_value <- pchisq(31743, 23805, lower.tail = FALSE)
p_value
```

IDK if reject null hypothesis that model fits well with data!!

### A GOF deviance test for the fitted model:
```{r}

p_value2 = pchisq(24881, 23611, lower.tail=F)  
p_value2
```
IDK if to reject or not 

### is the fitted model better than the null model?
```{r}

pchisq(31743-23805, 24881-23611, lower.tail=F)
```
p-value < 0.05, reject null model in favor of the fitted model.
p-value > 0.05, accept null model

##AUC of the model
```{r,results='markup'}
prob=predict(customerLogit, type = "response")
e <- roc(train_y~prob)
auc(e) # area-under-curve 
plot(e)

```


```{r}
proc=predict(customerLogit, type = "response", newdata = test_X)
test_X$proc=proc
roc <- roc(test_y~proc)
print(roc)

```
## McFadden
```{r}
library(pscl)
pR2(customerLogit)
```
the McFadden is 1.877608e-01 

### Akaike Information Criterion (AIC)
```{r}
AIC(customerLogit)

```


# Make prediction
## see 0.5 cut
```{r}

logitpredict.5 <- predict(customerLogit, newdata = test_X, type = "response") > 0.5

## I don't know if members are 1 or 0 
defult <- ifelse(logitpredict.5 =="TRUE", 1, 0)
crossTable = table(defult,test_y)
t <- as.data.frame(crossTable)
crossTable
```

### plot confution metrix
```{r}
ggplot(data =  t, mapping = aes(x = defult, y = test_y)) +
  geom_tile(aes(fill = Freq), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
  scale_fill_gradient(low = "#98c1d9", high = "#8f2d56") +
  theme_bw() + 
  theme(legend.position = "none") +
  labs(title = "Confution Matrix with Cutoff at 0.05")+
  xlab( "predected")+
  ylab( "original")
```

###The accuracy of the model of 0.5 cutoff :
```{r}
format(100*(crossTable[1,1]+crossTable[2,2])/sum(crossTable), digits=4)
```

## see 0.4 cut
```{r}

logitpredict.4 <- predict(customerLogit, newdata = test_X, type = "response") > 0.4
defult2 <- ifelse(logitpredict.4 =="TRUE", 1, 0)
crossTable4 = table(defult2,test_y)
d <- as.data.frame(crossTable4)
crossTable4
```
### The accuracy of the model of 0.4 cutoff :
```{r}
format(100*(crossTable4[1,1]+crossTable4[2,2])/sum(crossTable4), digits=4)
```

```{r}

ggplot(data = d , mapping = aes(x = defult2, y = test_y)) +
  geom_tile(aes(fill = Freq), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
  scale_fill_gradient(low = "#98c1d9", high = "#8f2d56") +
  theme_bw() +
  theme(legend.position = "none")+
  labs(title = "Confution Matrix with Cutoff at 0.04")+
  xlab( "predected")+
  ylab( "original")

```


# Topic2
## Step1: 
```{r}

```

## Step2: 
```{r}

```

## Step3: 
```{r}

```

## Step4: 
```{r}

```

## Step5: 
```{r}

```

## Step6: 
```{r}

```

## Step7: 
```{r}

```