---
title: "EDS"
output: html_document
date: "2022-11-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(purrr)   #to join all files
library(lubridate)# for duration of time
library(ModelMetrics)
library(pROC)
library(dplyr)
library(tidyr)
library(caret)
library(ggplot2)
```


# Topic1: 
#joining 6 months in one sheet
```{r}
#bind all the files in this path together
file.list <- list.files(pattern='*.csv')

# need an id-column with the file-names
file.list <- setNames(file.list, file.list)

#want only sheet 4, skip 1 row and name id column month
bike <-map_df(file.list, function(x) read.csv(x))

str(bike)
```

```{r}
bike%>%group_by(member_casual)%>%
  summarise(count = n())

#70% is unbalanced data set and this cut is more than that
```

#Preparing columns for modeling
```{r}

bike$rideable_type <- factor(as.integer(factor(bike$rideable_type)))
bike$start_station_id <- factor(bike$start_station_id)
bike$end_station_id <- factor(bike$end_station_id)
# make it to casual = 0, member= 1 
bike$member_casual<-factor(ifelse(bike$member_casual=='casual',0,1))

# split started_at/ ended_at to date column and time column
# change start_date/end_date to date type
bike$start_time <- format(as.POSIXct(bike$started_at), format = "%H:%M")
bike$end_time <- format(as.POSIXct(bike$ended_at), format = "%H:%M") 

# covert date to date type to get the time differnce
bike$Startedat = as.POSIXct(bike$started_at, format = "%Y-%m-%d %H:%M:%S")
bike$enddat = as.POSIXct(bike$ended_at, format = "%Y-%m-%d %H:%M:%S")
bike$Total_Time <- round(as.numeric(difftime(bike$enddat, bike$Startedat, units = "mins")),2)

# take only the day from the date
bike$start_date <- as.Date(bike$started_at)
bike$days <- format(bike$start_date, format = "%a")

```


#make the time as a duration of mints
```{r}
res <- hm(bike$start_time)# format to 'hours:minutes'
bike$startingm <- hour(res)*60 + minute(res)

#one hot encoding of days
bike <-bike %>% mutate(value = 1)  %>% spread(days, value,  fill = 0 )
```


## Drop non-needed columns
```{r}
#selecting the columns we want
want <- c('member_casual','rideable_type', 'Total_Time', 'start_station_id', 'end_station_id', 'startingm','Fri','Mon', 'Sat', 'Sun', 'Thu', 'Tue', 'Wed')

df2 <- bike[,(names(bike) %in% want)]

#Delete the na 
df<-na.omit(df2)

#make member_casual to be the first column
colnames(df)
df <- df %>%
  select('member_casual', everything())
```

# Check if we have unbalanced data
```{r}
df%>%group_by(member_casual)%>%
  summarise(count = n())

df %>% count(member_casual)
ggplot(df, aes(member_casual, fill = member_casual))+
  geom_bar()+
  scale_fill_brewer(palette = "BuPu")+
  guides(fill="none")+
  labs(title = "User membersip types", x= "types of memebership")+
  theme_classic()
```

# Dependent variables
```{r}
agesurvive = xtabs(~ member_casual + rideable_type, data = df)
chisq.test(agesurvive)
agesurvive2 = xtabs(~ member_casual + Total_Time, data = df)
chisq.test(agesurvive2)
agesurvive3 = xtabs(~ member_casual + start_station_id , data = df)
chisq.test(agesurvive3)
agesurvive4 = xtabs(~ member_casual + end_station_id , data = df)
chisq.test(agesurvive4)
agesurvive5 = xtabs(~ member_casual + startingm , data = df)
chisq.test(agesurvive5)
```

they are dependent factors due to low p-value

# scale and devide the data
```{r}
#scaleddf <- as.data.frame(scale(df[2:13], center = TRUE, scale = TRUE))
set.seed(321)
df_sample <- sample(2, nrow(df), replace=TRUE, prob=c(0.75, 0.25))


train_X <- df[df_sample==1, 1:12]
test_X <- df[df_sample==2, 1:12]


train_y <- df[df_sample==1, 1]
test_y <- df[df_sample==2, 1]

```


# Logistic model
```{r}
#deleted start_station_id and Wed coz the model says it is not much predictable 
customerLogit <- glm(train_y ~ end_station_id+Total_Time+rideable_type+ startingm*(Fri+Mon+Sat+Sun+Thu+Tue), data = train_X, family = "binomial")
summary(customerLogit)
```

```{r}
#coefftinc
expcoeff = exp(coef(customerLogit))
expcoeff
```

# See how well the model is doing by running suveral tests:
## Deviance tests
### A GOF deviance test for the null model:
```{r}
p_value <- pchisq(31728, 23813, lower.tail = FALSE)
p_value
```

IDK if reject null hypothesis that model fits well with data!!

### A GOF deviance test for the fitted model:
```{r}
p_value2 = pchisq(25770, 23708, lower.tail=F)  
p_value2
```
IDK if to reject or not 

### is the fitted model better than the null model?
```{r}

pchisq(31728-23813, 25770-23708, lower.tail=F)
```
p-value < 0.05, reject null model in favor of the fitted model.
p-value > 0.05, accept null model

##AUC of the model
```{r,results='markup'}
prob=predict(customerLogit, type = "response")
e <- roc(train_y~prob)
auc(e) # area-under-curve 
plot(e)

```

## McFadden
```{r}
library(pscl)
pR2(customerLogit)
```
the McFadden is 1.877608e-01 

### Akaike Information Criterion (AIC)
```{r}
AIC(customerLogit)

```
Lower AIC is better but I don't know if this is lower?


# Make prediction
## see 0.5 cut
```{r}

logitpredict.5 <- predict(customerLogit, newdata = test_X, type = "response") > 0.55

## I don't know if members are 1 or 0 
defult <- ifelse(logitpredict.5 =="TRUE", 1, 0)
crossTable = table(defult,test_y)
t <- as.data.frame(crossTable)
crossTable
```

### plot confution metrix
```{r}
ggplot(data =  t, mapping = aes(x = defult, y = test_y)) +
  geom_tile(aes(fill = Freq), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
  scale_fill_gradient(low = "#98c1d9", high = "#8f2d56") +
  theme_bw() + 
  theme(legend.position = "none") +
  labs(title = "Confution Matrix with Cutoff at 0.05")+
  xlab( "predected")+
  ylab( "original")
```

###The accuracy of the model of 0.5 cutoff :
```{r}
format(100*(crossTable[1,1]+crossTable[2,2])/sum(crossTable), digits=4)
```

## see 0.4 cut
```{r}

logitpredict.4 <- predict(customerLogit, newdata = test_X, type = "response") > 0.4
defult2 <- ifelse(logitpredict.4 =="TRUE", 1, 0)
crossTable4 = table(defult2,test_y)
d <- as.data.frame(crossTable4)
crossTable4
```
### The accuracy of the model of 0.4 cutoff :
```{r}
format(100*(crossTable4[1,1]+crossTable4[2,2])/sum(crossTable4), digits=4)
```
```{r}

ggplot(data = d , mapping = aes(x = defult2, y = test_y)) +
  geom_tile(aes(fill = Freq), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
  scale_fill_gradient(low = "#98c1d9", high = "#8f2d56") +
  theme_bw() +
  theme(legend.position = "none")+
  labs(title = "Confution Matrix with Cutoff at 0.04")+
  xlab( "predected")+
  ylab( "original")

```


# Topic2
## Step1: 
```{r}

```

## Step2: 
```{r}

```

## Step3: 
```{r}

```

## Step4: 
```{r}

```

## Step5: 
```{r}

```

## Step6: 
```{r}

```

## Step7: 
```{r}

```